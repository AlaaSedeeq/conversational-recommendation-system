{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6becf5-e6eb-4550-8dd3-ee9eb5c3c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334c3c89-8ecc-4474-9cb1-ffbff550553c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successful!\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Change to the project root directory\n",
    "os.chdir('/home/alaa/repos/seez-assignment')\n",
    "current_dir = os.getcwd()\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.insert(0, current_dir)\n",
    "\n",
    "try:\n",
    "    from src.utils.tools import read_dialogue\n",
    "    print(\"Import successful!\")\n",
    "except:\n",
    "    print(\"Failed\")\n",
    "\n",
    "import os\n",
    "\n",
    "from src.api_key import OPENAI_API_KEY\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2bfa39b-febc-42fa-a72e-c1d797f1ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List\n",
    "\n",
    "from src.common.config import ConfigBase\n",
    "\n",
    "class EmbeddingBase(ABC):\n",
    "    def __init__(self, config: ConfigBase):\n",
    "        self.config = config\n",
    "\n",
    "    @abstractmethod\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Embed a single query text.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text to embed.\n",
    "        \n",
    "        Returns:\n",
    "            List[float]: The embedding vector.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Embed a list of documents.\n",
    "        \n",
    "        Args:\n",
    "            texts (List[str]): The list of texts to embed.\n",
    "        \n",
    "        Returns:\n",
    "            List[List[float]]: A list of embedding vectors.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def __call__(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Make the class callable. This allows the class to be used as a function.\n",
    "        \n",
    "        Args:\n",
    "            texts (List[str]): The list of texts to embed.\n",
    "        \n",
    "        Returns:\n",
    "            List[List[float]]: A list of embedding vectors.\n",
    "        \"\"\"\n",
    "        return self.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f437ee0d-67b0-4245-9c79-58a0123e30a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-19 15:14:44,673: INFO: config: Config loaded successfully: config/config.yaml]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from typing import List, Union\n",
    "# from ..base_embedding import EmbeddingBase\n",
    "\n",
    "from src.common.config import ConfigBase, load_config\n",
    "\n",
    "class OpenAIEmbedding(EmbeddingBase):\n",
    "    def __init__(self, config: ConfigBase = load_config().embeddings):\n",
    "        super().__init__(config)\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\") or self.config.openai_api_key\n",
    "        if not openai.api_key:\n",
    "            raise ValueError(\"OpenAI API key must be provided either as an argument, \"\n",
    "                             \"in the OPENAI_API_KEY environment variable, or in the config.\")\n",
    "        self.model = self.config.parameters.embedding_model\n",
    "        self.client = openai.OpenAI()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Embed a single query text using OpenAI's API.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text to embed.\n",
    "        \n",
    "        Returns:\n",
    "            List[float]: The embedding vector.\n",
    "        \"\"\"\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        return self.client.embeddings.create(input=[text], model=self.model).data[0].embedding\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Embed a list of documents using OpenAI's API.\n",
    "        \n",
    "        Args:\n",
    "            texts (List[str]): The list of texts to embed.\n",
    "        \n",
    "        Returns:\n",
    "            List[List[float]]: A list of embedding vectors.\n",
    "        \"\"\"\n",
    "        texts = [text.replace(\"\\n\", \" \") for text in texts]\n",
    "        response = self.client.embeddings.create(input=texts, model=self.model)\n",
    "        return [data.embedding for data in response.data]\n",
    "\n",
    "    def __call__(self, texts: Union[str, List[str]]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Make the class callable. This allows the class to be used as a function.\n",
    "        \n",
    "        Args:\n",
    "            texts (Union[str, List[str]]): The text or list of texts to embed.\n",
    "        \n",
    "        Returns:\n",
    "            List[List[float]]: A list of embedding vectors.\n",
    "        \"\"\"\n",
    "        if isinstance(texts, str):\n",
    "            return [self.embed_query(texts)]\n",
    "        return self.embed_documents(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1163949e-4388-43e6-9156-ce7d9cf3fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "class Document(BaseModel):\n",
    "    page_content: str\n",
    "    metadata: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "class SearchEngineResponse(BaseModel):\n",
    "    status: bool\n",
    "    response: List\n",
    "    # [SearchResult]\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da3a0d96-2133-43ab-b400-6746d2d329fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from src.common.logger import logger\n",
    "from src.common.config import load_config, ConfigBase\n",
    "# from src.infrastructure.embeddings.base_embedding import EmbeddingBase\n",
    "# from src.multiAgent.infrastructure.embeddings.openai import OpenAIEmbedding\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# from .types import SearchEngineResponse\n",
    "\n",
    "class SimilaritySearchEngine(ABC):\n",
    "    \"\"\"Abstract base class for vector store functionalities.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config: Optional[ConfigBase] = None, \n",
    "        encoder: Optional[EmbeddingBase] = None, \n",
    "        **kwargs\n",
    "        ) -> None:\n",
    "        self.config = config or load_config().similarity_search\n",
    "        self.logger = logger\n",
    "        self.encoder = encoder\n",
    "        \n",
    "        if encoder is None:\n",
    "            self.encoder = OpenAIEmbeddings()\n",
    "        else:\n",
    "            self.encoder = encoder\n",
    "        \n",
    "        self.logger.info(\"Initialized SearchEngineBase!\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_embeddings(self) -> bool:\n",
    "        \"\"\"Abstract method for loading embeddings.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def embed_data(self) -> bool:\n",
    "        \"\"\"Abstract method for embedding data.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_embeddings(self) -> None:\n",
    "        \"\"\"Abstract method for saving embeddings.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def search(self, query: str, **kwargs) -> SearchEngineResponse:\n",
    "        \"\"\"Abstract method for finding similar items based on input.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ff2a512-0a59-4966-b9ba-9951d7aa2408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import warnings\n",
    "from typing import Optional\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "from src.common.logger import logger\n",
    "from src.common.config import ConfigBase\n",
    "\n",
    "from src.utils.tools import read_dialogue, read_user_data, read_jsonl, read_json, get_conversation_by_id\n",
    "\n",
    "# from src.infrastructure.embeddings.base_embedding import EmbeddingBase\n",
    "# from src.infrastructure.search_engine.base_engines import SimilaritySearchEngine\n",
    "# from ..types import SearchEngineResponse\n",
    "\n",
    "class FAISS_Search(SimilaritySearchEngine):\n",
    "    def __init__(\n",
    "            self,\n",
    "        config: Optional[ConfigBase] = None,\n",
    "        encoder: Optional[EmbeddingBase] = None,\n",
    "        **kwargs\n",
    "        ) -> None:\n",
    "        super().__init__(config, encoder, **kwargs)\n",
    "        \n",
    "        self.logger = logger\n",
    "        self.data = None\n",
    "        self.vectorstore = None\n",
    "        self.embeddings_loaded = False\n",
    "\n",
    "    def load_embeddings(self) -> bool:\n",
    "        if os.path.exists(self.config.embeddings,vectordb_path):\n",
    "            self.vectorstore = FAISS.load_local(\n",
    "                self.config.paths.vectordb, \n",
    "                self.encoder, \n",
    "                allow_dangerous_deserialization=True)\n",
    "            self.embeddings_loaded = True\n",
    "            return True\n",
    "        else:\n",
    "            self.logger.error(f\"Embeddings not found: {self.config.paths.vectordb}\")\n",
    "            return self.embed_data()\n",
    "\n",
    "    def _read_data(self):\n",
    "        \n",
    "        path = self.config.data.conversations\n",
    "        docs = read_dialogue(path)\n",
    "        \n",
    "        pattern = r\"(\\d+)\\n\\n((?:User:.*?\\n\\nAgent:.*?(?:\\n\\n|$))+)\"\n",
    "        matches = re.findall(pattern, docs, re.DOTALL)\n",
    "\n",
    "        documents = []\n",
    "        for match in matches:\n",
    "            dialogue_number = match[0]\n",
    "            dialogue_content = match[1].strip()\n",
    "            metadata = {\"dialogue_number\": dialogue_number}\n",
    "            documents.append(Document(page_content=dialogue_content, metadata=metadata))\n",
    "\n",
    "        return documents\n",
    "\n",
    "    def embed_data(self) -> bool:\n",
    "        try:\n",
    "            self.logger.info(\"Reading the data\")\n",
    "            docs = self._read_data()\n",
    "            self.logger.info(\"Embedding the data\")\n",
    "            self.vectorstore = FAISS.from_documents(docs, self.encoder)\n",
    "            self.embeddings_loaded = True\n",
    "            self.logger.info(\"Saving the embeddings\")\n",
    "            self.save_embeddings()\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to embed data: {e}\")\n",
    "            return False\n",
    "\n",
    "    def save_embeddings(self) -> None:\n",
    "        if self.vectorstore:\n",
    "            self.vectorstore.save_local(self.config.embeddings.vectordb_path)\n",
    "            self.logger.info(\"Embeddings saved locally.\")\n",
    "        else:\n",
    "            self.logger.error(\"No vectorstore to save embeddings from.\")\n",
    "\n",
    "    def search(\n",
    "        self, \n",
    "        query: str, \n",
    "        top_k: int = 5,\n",
    "        filter_neg: bool = True, \n",
    "    ) -> SearchEngineResponse:\n",
    "\n",
    "        if not self.embeddings_loaded:\n",
    "            if not self.load_embeddings():\n",
    "                return SearchEngineResponse(status=False, response=[])\n",
    "\n",
    "        query = query.strip()\n",
    "        self.logger.info(f\"Searching for: {query[:100]} ...\")\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            try:\n",
    "                docs = self.vectorstore.similarity_search_with_relevance_scores(query, k=top_k)\n",
    "                docs = sorted(docs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                if filter_neg:\n",
    "                    Hscore = docs[0][1]\n",
    "                    if Hscore < 0.0:\n",
    "                        self.logger.info(\"No similar items found in the item list for item `{}`.\".format(query))\n",
    "                        return SearchEngineResponse(status=True, response=[])\n",
    "                    qdocs = [d for d in docs if d[1] >= 0.0]\n",
    "                # else:\n",
    "                #     docs = [d for d in docs if d[1] >= self.config.min_similarity_thr]\n",
    "                #     qdocs = sorted(docs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                return SearchEngineResponse(status=True, response=qdocs)\n",
    "\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Similarity search error: \\n{e}\")\n",
    "                return SearchEngineResponse(status=False, response=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c31bef-9e20-413f-8f39-6fae1ee744d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7772f-7898-4bad-9563-ce430f180720",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ss._read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80e26f10-f357-49bf-991f-0b3bc523c2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-19 20:23:36,617: INFO: config: Config loaded successfully: config/config.yaml]\n",
      "[2024-11-19 20:23:36,946: INFO: 2264863557: Initialized SearchEngineBase!]\n"
     ]
    }
   ],
   "source": [
    "from src.common.config import load_config\n",
    "\n",
    "configs = load_config()\n",
    "\n",
    "ss = FAISS_Search(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0902ff75-9472-446e-935d-42b5fc2d5fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-19 20:24:00,605: INFO: _client: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"]\n",
      "[2024-11-19 20:24:14,509: INFO: _client: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"]\n",
      "[2024-11-19 20:24:29,902: INFO: _client: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"]\n",
      "[2024-11-19 20:24:42,084: INFO: _client: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"]\n",
      "[2024-11-19 20:24:57,184: INFO: _client: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"]\n",
      "[2024-11-19 20:25:07,245: INFO: _client: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"]\n",
      "[2024-11-19 20:25:07,248: INFO: _base_client: Retrying request to /embeddings in 16.201000 seconds]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ss.embed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d2d00f-fd21-4283-a4ea-303b643cbb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bf7e29-820b-44e7-9a8e-361ecadd7bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f69892-3d6f-4791-b909-056e39190eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1a786-4699-4848-bc45-f54503bc8a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d870e97f-4581-4801-a288-5b0dc251b044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6212b02-f3f8-475d-b447-49ba3a2f0431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e88f9a-ed25-4f52-a8b7-70c8f19b410f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45290e78-8966-46dd-8992-f37149e083ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb6eae0-3cd2-4ff1-8a45-4db749f0f50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9958d2-e4a8-4e43-806f-445853d5265c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad030292-02e0-4384-a25e-c002abaaef6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
