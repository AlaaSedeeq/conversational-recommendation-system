{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d5d367-30cf-41e3-8498-e6e8b1f3813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successful!\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Change to the project root directory\n",
    "os.chdir('/home/alaa/repos/seez-assignment')\n",
    "current_dir = os.getcwd()\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.insert(0, current_dir)\n",
    "\n",
    "try:\n",
    "    from src.utils.tools import read_dialogue\n",
    "    print(\"Import successful!\")\n",
    "except:\n",
    "    print(\"Failed\")\n",
    "\n",
    "import os\n",
    "\n",
    "from src.api_key import OPENAI_API_KEY\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822f1b60-4a5c-4f98-a62e-2e9795bc1feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    completed_nodes: Annotated[list[str], lambda x, y: list(set(x + y))]\n",
    "    latest_router_decision: str\n",
    "    user_context: Dict = {}\n",
    "    session_data: Dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e37f47dc-fb7e-4cea-a0ba-237a72366c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable, Dict, Any\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "class AssistantNode:\n",
    "    def __init__(\n",
    "            self, \n",
    "            name: str, system_prompt: str, \n",
    "            tools: List[Callable] = [], \n",
    "            completion_tool: str = \"\", \n",
    "            llm_chain: Runnable = None,\n",
    "            model_name=model_name\n",
    "            ) -> None:\n",
    "        \"\"\"\n",
    "        completion_tool: Is the tool binded to the node and once it is triggered, this\n",
    "        node is assigned as completed, and this node name 'name' is appended to the State\n",
    "        completed_node variable.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.system_prompt = system_prompt\n",
    "        self.tools = tools\n",
    "        self.completion_tool = completion_tool\n",
    "        self.llm = llm_chain or ChatOpenAI(model=model_name)\n",
    "\n",
    "    def update_system_prompt(self, prompt_config: dict) -> str:\n",
    "        # self.logger.debug(f\"Updating system prompt for {self.name}...\")\n",
    "        print(f\"Updating system prompt for {self.name}...\")\n",
    "        try:\n",
    "            if prompt_config and isinstance(prompt_config, dict):\n",
    "                formatted_prompt = self.system_prompt.format_map(prompt_config)\n",
    "                # self.logger.info(f\"Using prompt config for {self.name}\")\n",
    "                print(f\"Using prompt config for {self.name}\")\n",
    "            else:\n",
    "                formatted_prompt = self.system_prompt\n",
    "                # self.logger.info(f\"Using default prompt for {self.name},no prompt configs!\")\n",
    "                print(f\"Using default prompt for {self.name},no prompt configs!\")\n",
    "        except KeyError as e:\n",
    "            formatted_prompt = self.system_prompt\n",
    "            print(f\"Error formatting prompt for {self.name}: {e}\")\n",
    "            # self.logger.error(f\"Error formatting prompt for {self.name}: {e}\")\n",
    "        return formatted_prompt\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig) -> Dict[str, Any]:\n",
    "\n",
    "        print(f\"Current Node: {self.name.title()}\\n\")\n",
    "\n",
    "        system_prompt = self.update_system_prompt(\n",
    "            {**state[\"company_profile\"], **state[\"user_context\"], **state[\"session_data\"]}\n",
    "        )\n",
    "        assistant_prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt),(\"placeholder\", \"{messages}\")])\n",
    "        if self.tools:\n",
    "            llm_chain = assistant_prompt | self.llm.bind_tools(self.tools)\n",
    "        else:\n",
    "            llm_chain = assistant_prompt | self.llm\n",
    "\n",
    "        while True:\n",
    "            response = llm_chain.invoke(state)\n",
    "            # print(response)\n",
    "            if not response.tool_calls and (\n",
    "                not response.content\n",
    "                or isinstance(response.content, list)\n",
    "                and not response.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Your last response was empty. Please provide a correct response.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc6a52b-5058-4cd2-8298-bf987999564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def fetch_user_information(\n",
    "    state, \n",
    "    config\n",
    "):\n",
    "    print(); print(\"Current Node: Fetch User Info\")\n",
    "    configuration = config.get(\"configurable\", {})\n",
    "    user_id = configuration.get(\"user_id\", None)\n",
    "\n",
    "    user_data = {}\n",
    "    \n",
    "    if not user_id:\n",
    "        return {\n",
    "            \"user_context\": {\n",
    "                \"user_data\": user_data, \n",
    "                \"user_exists\": False,\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        from src.utils.tools import read_dialogue, read_user_data, read_jsonl, read_json, get_conversation_by_id\n",
    "\n",
    "        path = 'data/Movie'\n",
    "        final_data_path = '{}/final_data.jsonl'.format(path)\n",
    "        Conversation_path = '{}/Conversation.txt'.format(path)\n",
    "        item_map_path = '{}/item_map.json'.format(path)\n",
    "        \n",
    "        final_data = read_jsonl(final_data_path)\n",
    "        item_map = read_json(item_map_path)\n",
    "        Conversation = read_dialogue(Conversation_path)\n",
    "\n",
    "        user_information = read_user_data(final_data_path, user_id)\n",
    "        history_interaction = user_information['history_interaction']\n",
    "        user_might_likes = user_information['user_might_like']\n",
    "    \n",
    "        user_data = {\n",
    "                \"history_interaction\": [item_map[history_interaction[k]] for k in range(len(history_interaction))],\n",
    "                \"user_might_like\": [item_map[user_might_likes[k]] for k in range(len(user_might_likes))],\n",
    "                \"Conversation\": {}\n",
    "            }\n",
    "        Conversation_info = user_information['Conversation']\n",
    "        for j in range(len(Conversation_info)):\n",
    "            per_conversation_info = Conversation_info[j]['conversation_{}'.format(j + 1)]\n",
    "            user_likes_id = per_conversation_info['user_likes']\n",
    "            user_dislikes_id = per_conversation_info['user_dislikes']\n",
    "            rec_item_id = per_conversation_info['rec_item']\n",
    "            conversation_id = per_conversation_info['conversation_id']\n",
    "            dialogue = get_conversation_by_id(Conversation, conversation_id)\n",
    "            user_data['Conversation'][\"conversation_{}\".format(j + 1)] = {\n",
    "                \"user_likes\": [item_map[user_likes_id[k]] for k in range(len(user_likes_id))],\n",
    "                \"user_dislikes\": [item_map[user_dislikes_id[k]] for k in range(len(user_dislikes_id))],\n",
    "                \"rec_item\": [item_map[rec_item_id[k]] for k in range(len(rec_item_id))],\n",
    "                \"conversation_id\": conversation_id,\n",
    "                \"dialogue\": dialogue\n",
    "                }\n",
    "    \n",
    "        return {\n",
    "            \"user_context\": {\n",
    "                \"user_data\": user_data, \n",
    "                \"user_exists\": True,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {\n",
    "            \"user_context\": {\n",
    "                \"user_data\": user_data, \n",
    "                \"user_exists\": False,\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69efd808-c794-433d-bb65-3b0aeda682a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Node: Fetch User Info\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "state = State()\n",
    "config = config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": str(uuid.uuid4()),\n",
    "            \"user_id\": \"A30Q8X8B1S3GGT\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "state_ = fetch_user_information(state, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078fe21-5e6b-41bc-aad6-c0d7c3270457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any, Optional, Union, Tuple\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AnyMessage, AIMessage, ToolMessage\n",
    "from langchain_core.messages.tool import ToolCall\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class RouterResponse(BaseModel):\n",
    "    agent_name: str = Field(description=\"Name of the specialized agent best suited to handle the user's current request.\")\n",
    "    request: str = Field(description=\"Concise summary of user's request and relevant context that helps the selected agent understand and address the need effectively (optional).\")\n",
    "\n",
    "class Router:\n",
    "    def __init__(\n",
    "        self,\n",
    "        nodes: Union[List[str], Dict[str, str]], \n",
    "        system_prompt: str,\n",
    "        llm: Optional[ChatOpenAI] = None,\n",
    "        model: str = \"\",\n",
    "        default_node: Optional[str] = None,\n",
    "        max_preview: int = 100,\n",
    "        max_history: int = 10,\n",
    "        k_latest_messages: int = 6,\n",
    "        max_assistant_preview: int = 20,\n",
    "        default_model: str = \"gpt-4o\"\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize Router node.\n",
    "        \n",
    "        Args:\n",
    "            nodes: List of node names or Dict of node names to descriptions\n",
    "            llm: Language model instance (optional)\n",
    "            model: Model name (optional)\n",
    "            system_prompt: System prompt for the router (optional)\n",
    "            default_node: Default node to route to (optional)\n",
    "        \"\"\"\n",
    "        self.model = model if \"gpt-4o\" in model else default_model\n",
    "        self.llm = llm or ChatOpenAI(model=self.model).with_structured_output(RouterResponse)\n",
    "        self.nodes = nodes\n",
    "        self.default_node = default_node or self._get_default_node()\n",
    "        self.system_prompt = system_prompt\n",
    "        self.max_preview = max_preview\n",
    "        self.max_history = max_history\n",
    "        self.k_latest_messages = k_latest_messages\n",
    "        self.max_assistant_preview = max_assistant_preview\n",
    "\n",
    "    def _get_default_node(self) -> str:\n",
    "        \"\"\"Get default node from nodes configuration.\"\"\"\n",
    "        return (\n",
    "            self.nodes[0] if isinstance(self.nodes, list) \n",
    "            else list(self.nodes.keys())[0]\n",
    "        )\n",
    "\n",
    "    def _format_message(self, message: AnyMessage) -> Optional[str]:\n",
    "        \"\"\"Format a single message for history.\"\"\"\n",
    "        if isinstance(message, HumanMessage):\n",
    "            return f\"User: {message.content}\"\n",
    "        elif isinstance(message, AIMessage) and message.content:\n",
    "            preview = message.content[:self.max_preview] + \"...(preview)\"\n",
    "            return f\"Assistant: {preview}\"\n",
    "        return None\n",
    "\n",
    "    def _prepare_message_history(self, messages: List[AnyMessage]) -> str:\n",
    "        \"\"\"Prepare message history for router context.\"\"\"\n",
    "        formatted_messages = [\n",
    "            msg for msg in (self._format_message(m) for m in messages)\n",
    "            if msg is not None\n",
    "        ]\n",
    "        return \"\\n\".join(formatted_messages)\n",
    "\n",
    "    def _get_nodes_description(self, state: State) -> Tuple[List[str], str]:\n",
    "        \"\"\"Get available nodes and their description.\"\"\"\n",
    "        completed_nodes = state.get(\"completed_nodes\", [])\n",
    "\n",
    "        if isinstance(self.nodes, list):\n",
    "            available_nodes = [\n",
    "                node for node in self.nodes \n",
    "                if node not in completed_nodes\n",
    "            ]\n",
    "            nodes_description = \", \".join(available_nodes)\n",
    "        else:\n",
    "            available_nodes = {\n",
    "                node: desc \n",
    "                for node, desc in self.nodes.items() \n",
    "                if node not in completed_nodes\n",
    "            }\n",
    "            nodes_description = \"\\n\".join(\n",
    "                f\"- {node}: {desc}\" \n",
    "                for node, desc in available_nodes.items()\n",
    "            )\n",
    "            available_nodes = list(available_nodes.keys())\n",
    "\n",
    "        return available_nodes, nodes_description\n",
    "\n",
    "    def _create_router_messages(self, \n",
    "                              state: State, \n",
    "                              nodes_description: str) -> List[Union[SystemMessage, HumanMessage]]:\n",
    "        \"\"\"Create messages for router LLM.\"\"\"\n",
    "        system_prompt = (\n",
    "            f\"{self.system_prompt}\\n\\n\"\n",
    "            f\"Available agents:\\n{nodes_description}\\n\\n\"\n",
    "            \"Only return agent name\"\n",
    "        )\n",
    "        latest_messages = self._prepare_message_history(state.get(\"messages\", []))\n",
    "        user_msg = f\"Chat History:\\n{latest_messages}\\n\\nAgents Name:\"\n",
    "        \n",
    "        return [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=user_msg)\n",
    "        ]\n",
    "\n",
    "    def _add_router_tool(self, router_response: RouterResponse) -> Dict[str, Any]:\n",
    "        \"\"\"Add route tool to state.\"\"\"\n",
    "        routing_message = (\n",
    "            f\"The assistant is now the {router_response.agent_name}. \"\n",
    "            \"Reflect on the above conversation between the host assistant and the user. \"\n",
    "            \"Do not mention who you are - just act as the proxy for the assistant.\"\n",
    "            )\n",
    "        messages = [\n",
    "            AIMessage(content=\"\", tool_calls=[ToolCall(name=\"Router\", args={\"agent_name\": router_response.agent_name, \"request\": router_response.request}, id=\"\")]),\n",
    "            ToolMessage(content=routing_message, name=\"Router\", tool_call_id=\"\"),\n",
    "            ]\n",
    "        return messages\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig) -> Dict[str, Any]:\n",
    "        \"\"\"Route to appropriate node based on conversation state.\"\"\"\n",
    "        print(\"\\nCurrent Node: Router\")\n",
    "        \n",
    "        available_nodes, nodes_description = self._get_nodes_description(state)\n",
    "        \n",
    "        if not available_nodes:\n",
    "            print(f\"Router selected default node: {self.default_node}\")\n",
    "            return {\"latest_router_decision\": self.default_node}\n",
    "\n",
    "        messages = self._create_router_messages(state, nodes_description)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                response = self.llm.invoke(messages)\n",
    "                node_name = response.agent_name\n",
    "\n",
    "                if node_name and node_name in available_nodes:\n",
    "                    break\n",
    "                    \n",
    "                messages.append(\n",
    "                    HumanMessage(\n",
    "                        content=\"Not a valid node! Please try again. \"\n",
    "                        f\"Your output should be an agent name from the available agents {available_nodes}.\"\n",
    "                    )\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error in router: {e}\")\n",
    "                return {\"latest_router_decision\": self.default_node}\n",
    "\n",
    "        print(f\"Router selected: {node_name}\")\n",
    "        \n",
    "        messages = self._add_router_tool(response)\n",
    "        return {\"messages\": messages,  \"latest_router_decision\": node_name}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
